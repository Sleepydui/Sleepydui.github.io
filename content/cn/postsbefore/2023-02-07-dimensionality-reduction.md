---
title: "关于文本数据降维投影的思考"
date: 2023-02-07T15:36:57+08:00
author: "陈昕悦"
slug:
draft: false
toc: false
---
- 文本数据是我在可视化研究中最常使用的数据类型
  -  俄乌新闻可视化画contour的时候我曾用过TF-IDF与PCA
  	-   但其实不明白背后的原理
  	-   而且contour的效果并不好（1）overlap太多（2）stopword并没有过滤掉太多没有实际意义的词导致聚类含义不明
  -  在阅读wiki时，我发现lab的习惯是先用降维投影观察一下数据
    -   如media bias （http://vis.pku.edu.cn/wiki/doku.php?id=visgroup:projects:biasvis:data）

- PCA（Principal Component Analysis）
  - 使用 PCA 算法的步骤如下：
    1. 用TfidfVectorizer() 对输入的文本数据进行特征提取，生成特征矩阵vectors
    2. 然后，使用 PCA（Principal Component Analysis）算法对特征矩阵 vectors 进行降维，降维后的结果存储在 vectorspca 中。n_components 参数代表降维后的维数，即将特征矩阵降维为 2 维。
  - PCA 算法是一种常用的降维算法，它的原理是在保证数据的总方差不变的情况下，对数据进行线性变换，使得变换后的数据具有最大的方差。这样，在降维的同时，尽量保留原始数据的信息。
  - 因此，PCA 降维是通过找到数据的主成分，以尽可能保证数据总方差不变的情况下降低数据维数来实现降维的。

- T-SNE (t-Distributed Stochastic Neighbor Embedding) 
  - T-SNE是一种高维数据的降维算法，可以帮助我们将高维的数据降到低维，并且保持数据之间的相似性关系。
  - 它的使用方法很简单，我们只需要提供原始的高维数据和降维后的维数，T-SNE 就可以计算出一个新的低维数据，并且用这个低维数据来可视化原始数据。
  - T-SNE 的一个重要依据是数据之间的相似性关系，它通过计算数据间的近邻关系来生成降维数据，从而可以更好地呈现数据的分布。
      1. T-SNE 计算相似性的原理基于两个假设：数据之间的相似性关系以及低维数据的分布更加集中。
      2. 在原始的高维数据中，T-SNE 计算出数据之间的相似性，它将相似的数据映射到近邻关系，而不相似的数据映射到远离关系。
      3. 然后，T-SNE 在低维数据中重新计算数据之间的相似性，使得相似的数据仍然是近邻关系，而不相似的数据仍然是远离关系。最终，T-SNE 将低维数据放到二维或三维平面上，以可视化方式呈现数据分布。
      4. 通过这样的过程，T-SNE 可以保持原始数据中数据之间的相似性关系，并且使得低维数据的分布更加集中，从而更好地呈现数据的分布情况。
  - 通常情况下，T-SNE 适用于处理非线性数据，因为它可以捕捉到数据之间的非线性关系。它在许多的数据分析场景中都有很好的应用，比如文本分类、图像分类、生物信息学等。


- SVD（Singular Value Decomposition）算法是一种数学分解方法，它可以将一个矩阵分解为三个矩阵的乘积，分别是左奇异矩阵、奇异值矩阵和右奇异矩阵。
  - 在机器学习和数据分析中，SVD 算法常用来降维，去噪和特征提取。例如，在推荐系统中，可以使用 SVD 算法来研究用户对物品的评分，以实现更准确的推荐。
  - 使用 SVD 算法的步骤如下：
    1. 导入必要的库，并载入数据集。
    2. 对数据集进行 SVD 分解。
    3. 应用分解结果，进行降维、去噪或特征提取。
    4. 对结果进行评估，并选择最优的降维结果。
  - 数学解释：一个矩阵 A 的 SVD 分解是将 A 分解为三个矩阵的乘积：A = UΣV^T，
    1. 其中U 是一个左奇异矩阵，其列向量为 A 的左奇异向量。
    2. Σ 是一个对角矩阵，其对角线上的元素是 A 的奇异值，即 A 的左奇异向量与右奇异向量的内积。
    3. V^T 是 A 的右奇异矩阵，其行向量为 A 的右奇异向量。
  - 分解矩阵的作用：
    1. 降维：SVD 可以用于降维，因为可以通过保留较少的奇异值和对应的左右奇异向量来近似矩阵。
    2. 对矩阵进行特征提取：通过 SVD 可以提取出矩阵的主要特征，对于数据挖掘和数据分析非常有用。
    3. 对矩阵进行矩阵运算：SVD 分解后的矩阵具有结构性，可以用于矩阵的快速运算。
    4. 对矩阵进行压缩：SVD 可以用于数据压缩，因为可以通过保留较少的奇异值和对应的左右奇异向量来近似矩阵。

- 文本特征提取（BERT 和 TF-IDF 是不同的文本特征提取方法，两者生成的特征矩阵不同）
  - BERT：BERT 是一种 Transformer-based 模型，是一种预训练的深度双向语言模型。它的特征提取方法是通过语义理解文本的方式生成的，并不是通过词袋模型的方式生成的。BERT 通过全词覆盖来理解词语的语境，这些理解被转化为对词语的向量表示。该模型的输入是一个文本的句子，它的输出是一个固定长度的向量，这个向量可以看作是这个句子的特征向量。
  - TF-IDF：TF-IDF 是一种常用的文本特征提取方法，它通过词频和逆文档频率的方式生成的。词频表示一个词语在文档中出现的频率，逆文档频率是一个词语在整个语料库中的出现频率的倒数。TF-IDF 特征矩阵的每一列对应一个词语，每一行对应一个文档，每一个元素是一个文档中一个词语的 TF-IDF 值。
  - 生成的特征矩阵和原始文本数据是通过向量表示相对应的。对于 BERT，特征向量是语义表示；对于 TF-IDF，特征矩阵是文档中词语出现的频率和在整个语料库中的重要性